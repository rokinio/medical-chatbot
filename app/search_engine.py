"""
Ù…ÙˆØªÙˆØ± Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø±Ø§ÛŒ ÛŒØ§ÙØªÙ† Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø´Ø§Ø¨Ù‡
"""

import streamlit as st
import numpy as np
import json
import os

from config import *
from data_manager import load_model, load_faiss

def search_with_faiss_cached(query, top_k=5, selected_source=None):
    """Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² FAISS Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØª Ú©Ø´"""
    # Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù„ÛŒØ¯ Ú©Ø´
    cache_key = f"{query}_{top_k}_{selected_source}"
    
    # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ù†ØªÛŒØ¬Ù‡ Ø¯Ø± Ú©Ø´
    if 'search_cache' not in st.session_state:
        st.session_state.search_cache = {}
        
    if cache_key in st.session_state.search_cache:
        st.write("ğŸ’¡ Ù†ØªÛŒØ¬Ù‡ Ø§Ø² Ú©Ø´ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø´Ø¯!")
        return st.session_state.search_cache[cache_key]
    
    try:
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ùˆ Ø§ÛŒÙ†Ø¯Ú©Ø³
        model = load_model()
        index, metadata = load_faiss()
        
        if model is None or index is None or metadata is None:
            return search_text(query, top_k, selected_source)
        
        # ØªØ¨Ø¯ÛŒÙ„ Ø³Ø¤Ø§Ù„ Ø¨Ù‡ embedding
        query_embedding = model.encode([query])
        
        # Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± FAISS
        distances, indices = index.search(np.array(query_embedding, dtype=np.float32), top_k * 3)  # Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¨ÛŒØ´ØªØ± Ø¨Ø±Ø§ÛŒ ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù†
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³Ø¤Ø§Ù„Ø§Øª Ù…Ø´Ø§Ø¨Ù‡
        results = []
        sources = metadata.get("sources", ["unknown"] * len(metadata["questions"]))
        
        for i, idx in enumerate(indices[0]):
            if idx < len(metadata["questions"]):
                question = metadata["questions"][idx]
                source = sources[idx] if idx < len(sources) else "unknown"
                
                # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ù†Ø¨Ø¹ Ø§Ú¯Ø± Ù…Ù‚Ø¯Ø§Ø± Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯
                if selected_source == "Ù‡Ù…Ù‡" or selected_source is None or source == selected_source:
                    results.append({"question": question, "source": source})
                
                # Ø¬Ù…Ø¹ Ø¢ÙˆØ±ÛŒ Ø¨Ù‡ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ú©Ø§ÙÛŒ
                if len(results) >= top_k:
                    break
        
        # Ø§Ú¯Ø± Ø¨Ù‡ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ú©Ø§ÙÛŒ Ù†ØªÛŒØ¬Ù‡ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ØŒ Ø§Ø² Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…ØªÙ†ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        if not results:
            results = search_text(query, top_k, selected_source)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ú©Ø´
        st.session_state.search_cache[cache_key] = results
        return results
    
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¬Ø³ØªØ¬ÙˆÛŒ FAISS: {e}")
        # Ø¨Ø±Ú¯Ø´Øª Ø¨Ù‡ Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…ØªÙ†ÛŒ Ø³Ø§Ø¯Ù‡ Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§
        return search_text(query, top_k, selected_source)

def search_text(query, top_k=5, selected_source=None):
    """Ø¬Ø³ØªØ¬ÙˆÛŒ Ø³Ø§Ø¯Ù‡ Ù…ØªÙ†ÛŒ (Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù¾Ø´ØªÛŒØ¨Ø§Ù†)"""
    try:
        if not os.path.exists(PROCESSED_QUESTIONS_PATH):
            st.error(f"ÙØ§ÛŒÙ„ Ø³ÙˆØ§Ù„Ø§Øª ({PROCESSED_QUESTIONS_PATH}) ÛŒØ§ÙØª Ù†Ø´Ø¯!")
            return []
            
        with open(PROCESSED_QUESTIONS_PATH, "r", encoding="utf-8") as f:
            data = json.load(f)
        
        # Ø¬Ø³ØªØ¬ÙˆÛŒ Ø³Ø§Ø¯Ù‡ Ù…ØªÙ†ÛŒ
        matching_questions = []
        
        if isinstance(data, list):
            for entry in data:
                if "question" in entry:
                    question = entry["question"].lower()
                    source = entry.get("source", "unknown")
                    
                    # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ù†Ø¨Ø¹ Ø§Ú¯Ø± Ù…Ù‚Ø¯Ø§Ø± Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯
                    if selected_source == "Ù‡Ù…Ù‡" or selected_source is None or source == selected_source:
                        if any(word.lower() in question for word in query.lower().split()):
                            matching_questions.append({"question": entry["question"], "source": source})
                            if len(matching_questions) >= top_k:
                                break
        
        return matching_questions
    
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…ØªÙ†ÛŒ: {e}")
        return []

def get_question_category(question):
    """ØªØ´Ø®ÛŒØµ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ ÛŒÚ© Ø³ÙˆØ§Ù„"""
    question_lower = question.lower()
    categories = MEDICAL_CATEGORIES
    matching_categories = []
    
    for category, keywords in categories.items():
        for keyword in keywords:
            if keyword in question_lower:
                matching_categories.append(category)
                break
    
    return matching_categories if matching_categories else ["Ù…ØªÙØ±Ù‚Ù‡"]

def filter_by_category(results, category):
    """ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ù†ØªØ§ÛŒØ¬ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ"""
    if category == "Ù‡Ù…Ù‡":
        return results
        
    filtered_results = []
    for result in results:
        q_categories = get_question_category(result["question"])
        if category in q_categories:
            filtered_results.append(result)
    
    return filtered_results